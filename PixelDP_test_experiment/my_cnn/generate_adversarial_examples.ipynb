{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import mnist_input\n",
    "import mnist_model\n",
    "reload(mnist_model)\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mnist_util\n",
    "reload(mnist_util)\n",
    "mnist = mnist_input.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#checkpoint_path = \"/home/justin/Programming/AdverserialMNIST/saved_models/l1reg.ckpt\"\n",
    "checkpoint_path = \"/home/justin/Programming/AdverserialMNIST/saved_models/baseline_40epochs.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", shape=[784])\n",
    "y_ = tf.placeholder(\"float\", shape=[10])\n",
    "y_conv, keep_prob, variable_dict = mnist_model.model(x)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "grad = tf.gradients(cross_entropy, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "saver = tf.train.Saver(variable_dict)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "saver.restore(sess, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for idx in xrange(len(mnist.test.images)):\n",
    "    if idx % 100 == 0:\n",
    "        print idx\n",
    "    image = mnist.test.images[idx]\n",
    "    y_onehot = mnist.test.labels[idx]\n",
    "    label = np.argmax(y_onehot)\n",
    "    pred = sess.run(y_conv, feed_dict={x:image, keep_prob:1.0})\n",
    "    label1 = np.argmax(pred)\n",
    "\n",
    "    np_grad = sess.run(grad, feed_dict={x:image, y_:y_onehot, keep_prob:1.0})\n",
    "    signed_grad = np.sign(np_grad[0])\n",
    "    grad_norm = sum([np.abs(w) for w in np_grad[0]])\n",
    "    \n",
    "    for GRADIENT_STEP in np.linspace(.01, .1, 10):\n",
    "        adv_image = GRADIENT_STEP * signed_grad + image\n",
    "        pred2 = sess.run(y_conv, feed_dict={x:adv_image, keep_prob:1.0})\n",
    "        label2 = np.argmax(pred2)\n",
    "\n",
    "        series = pd.Series([idx, label, label1, label2, grad_norm, pred, pred2, image, adv_image, \n",
    "                            GRADIENT_STEP, np_grad],\n",
    "                          index = [\"Idx\", \"True Label\", \"Predicted Label\", \"Predicted Label Adverserial\",\\\n",
    "                                   \"Gradient Norm\", \"Predicted Probs\", \"Predicted Probs Adverserial\", \"Image\",\\\n",
    "                                   \"Adverserial Image\", \"Gradient Step\", \"Gradient\"])\n",
    "        df = df.append(series, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19992\n"
     ]
    }
   ],
   "source": [
    "#pickle the results\n",
    "df[\"Fooling Image (Y/N)\"] = df.apply(lambda row: row[\"Predicted Label\"] != row[\"Predicted Label Adverserial\"],\n",
    "                                     axis = 1)\n",
    "print sum(df[\"Fooling Image (Y/N)\"])\n",
    "import pickle\n",
    "with open(\"/home/justin/Programming/AdverserialMNIST/saved_models/baseline_40epochs_results.pkl\", \"wb\") as pkl_file:\n",
    "    pickle.dump(df, pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19992\n",
      "5690\n"
     ]
    }
   ],
   "source": [
    "df[\"Fooling Image (Y/N)\"] = df.apply(lambda row: row[\"Predicted Label\"] != row[\"Predicted Label Adverserial\"],\n",
    "                                     axis = 1)\n",
    "print sum(df[\"Fooling Image (Y/N)\"])\n",
    "print df[\"Gradient Norm\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Adverserial Image', 'Gradient', 'Gradient Norm', 'Gradient Step',\n",
       "       'Idx', 'Image', 'Predicted Label', 'Predicted Label Adverserial',\n",
       "       'Predicted Probs', 'Predicted Probs Adverserial', 'True Label',\n",
       "       'Fooling Image (Y/N)'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_not_null = df.dropna(subset = [\"Gradient Norm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9.431000e+04\n",
       "mean     4.952379e+00\n",
       "std      5.293059e+01\n",
       "min      7.232291e-26\n",
       "25%      4.756640e-15\n",
       "50%      5.789651e-12\n",
       "75%      4.962725e-09\n",
       "max      8.076515e+02\n",
       "Name: Gradient Norm, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_null[\"Gradient Norm\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Step</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>0.009755</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.02</th>\n",
       "      <td>0.025448</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.03</th>\n",
       "      <td>0.052805</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.04</th>\n",
       "      <td>0.074011</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>0.103064</td>\n",
       "      <td>972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.06</th>\n",
       "      <td>0.138692</td>\n",
       "      <td>1308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.07</th>\n",
       "      <td>0.190860</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.08</th>\n",
       "      <td>0.248754</td>\n",
       "      <td>2346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.09</th>\n",
       "      <td>0.322765</td>\n",
       "      <td>3044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.388506</td>\n",
       "      <td>3664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mean   sum\n",
       "Gradient Step                \n",
       "0.01           0.009755    92\n",
       "0.02           0.025448   240\n",
       "0.03           0.052805   498\n",
       "0.04           0.074011   698\n",
       "0.05           0.103064   972\n",
       "0.06           0.138692  1308\n",
       "0.07           0.190860  1800\n",
       "0.08           0.248754  2346\n",
       "0.09           0.322765  3044\n",
       "0.10           0.388506  3664"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df_not_null.groupby(\"Gradient Step\")[\"Fooling Image (Y/N)\"].aggregate([np.mean, np.sum])\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby(\"Gradient Step\")[\"Fooling Image (Y/N)\"].aggregate([np.mean, np.sum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Step</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>0.0090</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.02</th>\n",
       "      <td>0.0230</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.03</th>\n",
       "      <td>0.0405</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.04</th>\n",
       "      <td>0.0705</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>0.1120</td>\n",
       "      <td>1120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.06</th>\n",
       "      <td>0.1619</td>\n",
       "      <td>1619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.07</th>\n",
       "      <td>0.2221</td>\n",
       "      <td>2221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.08</th>\n",
       "      <td>0.2913</td>\n",
       "      <td>2913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.09</th>\n",
       "      <td>0.3516</td>\n",
       "      <td>3516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.4083</td>\n",
       "      <td>4083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean   sum\n",
       "Gradient Step              \n",
       "0.01           0.0090    90\n",
       "0.02           0.0230   230\n",
       "0.03           0.0405   405\n",
       "0.04           0.0705   705\n",
       "0.05           0.1120  1120\n",
       "0.06           0.1619  1619\n",
       "0.07           0.2221  2221\n",
       "0.08           0.2913  2913\n",
       "0.09           0.3516  3516\n",
       "0.10           0.4083  4083"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25338\n"
     ]
    }
   ],
   "source": [
    "bad_samples = df[df.apply(lambda row: row[\"Predicted Label\"] != \\\n",
    "                          row[\"Predicted Label Adverserial\"], axis = 1)].dropna(subset = [\"Gradient Norm\"])\n",
    "print len(bad_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Label</th>\n",
       "      <th>Predicted Label</th>\n",
       "      <th>Predicted Label Adverserial</th>\n",
       "      <th>Gradient Norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.346662e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.346662e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.346662e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.346662e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.346662e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.346662e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.346662e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.346662e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2.889365e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2.889365e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    True Label  Predicted Label  Predicted Label Adverserial  Gradient Norm\n",
       "22           1                1                            4   1.346662e-11\n",
       "23           1                1                            4   1.346662e-11\n",
       "24           1                1                            4   1.346662e-11\n",
       "25           1                1                            4   1.346662e-11\n",
       "26           1                1                            4   1.346662e-11\n",
       "27           1                1                            4   1.346662e-11\n",
       "28           1                1                            4   1.346662e-11\n",
       "29           1                1                            4   1.346662e-11\n",
       "61           4                4                            9   2.889365e-10\n",
       "62           4                4                            9   2.889365e-10"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_samples[[\"True Label\", \"Predicted Label\", \"Predicted Label Adverserial\",\\\n",
    "                               \"Gradient Norm\"]][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f09c96053d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Adverserial: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f09c009ae50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 40\n",
    "row = bad_samples.iloc[idx]\n",
    "img1 = row[\"Image\"]\n",
    "img2 = row[\"Adverserial Image\"]\n",
    "print \"Predicted: %d\" %row[\"Predicted Label\"]\n",
    "mnist_util.plot_mnist_digit(np.reshape(img1, [28,28]))\n",
    "\n",
    "print \"Predicted Adverserial: %d\" %row[\"Predicted Label Adverserial\"]\n",
    "mnist_util.plot_mnist_digit(np.reshape(img2, [28,28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 1, Predicted: 1\n",
      "Actual 1hot:\n",
      "[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "Predicted 1hot:\n",
      "[  4.42696859e-07   9.99982834e-01   6.37616552e-07   7.60669025e-07\n",
      "   6.41909423e-07   3.53572425e-08   2.74042145e-06   1.85791990e-07\n",
      "   1.17788386e-05   5.02189543e-08] 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABI8Ram2NdruIC2gQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff0f9bdf350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "tup = bad_images[11]\n",
    "print \"Actual: %d, Predicted: %d\"%(tup[1], tup[2])\n",
    "print \"Actual 1hot:\"\n",
    "print tup[3]\n",
    "print \"Predicted 1hot:\"\n",
    "print tup[4], np.argmax(tup[4])\n",
    "\n",
    "mnist_util.plot_mnist_digit(np.reshape(tup[0], [28,28]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
