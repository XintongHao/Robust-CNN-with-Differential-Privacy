{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "##This notebook trains the same CNN model, but with l1 regularization to encourage smaller and sparser weights\n",
    "##We use 10^-3 learning rate instead of 10^-4, we also let the model run longer. After 50000 batches of size 50 \n",
    "##(~41 epochs) the l1 norm of the weights was 28000, compared to 230000 for the baseline model\n",
    "\n",
    "import mnist_input\n",
    "import mnist_model\n",
    "reload(mnist_model)\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "mnist = mnist_input.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"/home/justin/Programming/AdverserialMNIST/saved_models/l1reg.ckpt\"\n",
    "x, y_ = mnist_model.place_holders()\n",
    "y_conv, keep_prob, variable_dict = mnist_model.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define the l1-loss\n",
    "absolute_sums = []\n",
    "for variable in variable_dict.values():\n",
    "    absolute_sums.append(tf.reduce_sum(tf.abs(variable)))\n",
    "l1_sum = tf.add_n(absolute_sums)\n",
    "\n",
    "#count the number where are > 0, surprisingly \n",
    "variable_non_zero_counts = []\n",
    "for variable in variable_dict.values():\n",
    "    variable_non_zero_counts.append(tf.reduce_sum(tf.cast(tf.greater(tf.abs(variable), tf.constant(0.000001)), \"float\")))\n",
    "num_non_zero_op = tf.add_n(variable_non_zero_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#experiments without l1 regularization showed cross entropy in the range of [1,10] and\n",
    "#l1_sum around 236000\n",
    "C = 1.0/20000.0 #define the regularization constant, this way\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(tf.clip_by_value(y_conv,1e-10,1.0))) #avoid 0*log(0) error\n",
    "l1_loss = cross_entropy + C*l1_sum\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(l1_loss)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "saver = tf.train.Saver(variable_dict)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "#saver.restore(sess, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_accuracy(prob = 1.0):\n",
    "    idx = 0\n",
    "    batch_size = 500\n",
    "    num_correct = 0\n",
    "    while(idx < len(mnist.test.images)):\n",
    "        num_correct += np.sum(correct_prediction.eval(feed_dict = {\n",
    "               x: mnist.test.images[idx:idx+batch_size], \n",
    "               y_: mnist.test.labels[idx:idx+batch_size], keep_prob: prob\n",
    "                    }))\n",
    "        idx+=batch_size\n",
    "    return float(num_correct)/float(len(mnist.test.images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, cross_ent: 0.096167, l1_norm: 31424.892578, train_acc: 1.000000, test_acc: 0.992100, loss: 1.667411, num_non_zero: 1618356\n",
      "step 1000, cross_ent: 0.002629, l1_norm: 31625.417969, train_acc: 1.000000, test_acc: 0.990700, loss: 1.583899, num_non_zero: 1618353\n",
      "step 2000, cross_ent: 0.049666, l1_norm: 30756.298828, train_acc: 1.000000, test_acc: 0.992200, loss: 1.587481, num_non_zero: 1618899\n",
      "step 3000, cross_ent: 0.001304, l1_norm: 31521.630859, train_acc: 1.000000, test_acc: 0.993200, loss: 1.577386, num_non_zero: 1619387\n",
      "step 4000, cross_ent: 0.000730, l1_norm: 29586.613281, train_acc: 1.000000, test_acc: 0.992000, loss: 1.480060, num_non_zero: 1619878\n",
      "step 5000, cross_ent: 0.002505, l1_norm: 28110.949219, train_acc: 1.000000, test_acc: 0.991600, loss: 1.408052, num_non_zero: 1619748\n",
      "step 6000, cross_ent: 0.023622, l1_norm: 30574.423828, train_acc: 1.000000, test_acc: 0.991900, loss: 1.552343, num_non_zero: 1613089\n",
      "step 7000, cross_ent: 0.009392, l1_norm: 31347.361328, train_acc: 1.000000, test_acc: 0.990600, loss: 1.576760, num_non_zero: 1616365\n",
      "step 8000, cross_ent: 0.000158, l1_norm: 29577.751953, train_acc: 1.000000, test_acc: 0.993100, loss: 1.479046, num_non_zero: 1618181\n",
      "step 9000, cross_ent: 0.000709, l1_norm: 28879.160156, train_acc: 1.000000, test_acc: 0.993000, loss: 1.444667, num_non_zero: 1621275\n",
      "step 10000, cross_ent: 0.038391, l1_norm: 30883.021484, train_acc: 1.000000, test_acc: 0.994000, loss: 1.582542, num_non_zero: 1617137\n",
      "step 11000, cross_ent: 0.000670, l1_norm: 30710.630859, train_acc: 1.000000, test_acc: 0.992000, loss: 1.536201, num_non_zero: 1619248\n",
      "step 12000, cross_ent: 0.006789, l1_norm: 30004.511719, train_acc: 1.000000, test_acc: 0.993300, loss: 1.507015, num_non_zero: 1618850\n",
      "step 13000, cross_ent: 0.000355, l1_norm: 29190.615234, train_acc: 1.000000, test_acc: 0.991100, loss: 1.459887, num_non_zero: 1620625\n",
      "step 14000, cross_ent: 0.000069, l1_norm: 27661.472656, train_acc: 1.000000, test_acc: 0.994200, loss: 1.383142, num_non_zero: 1623737\n",
      "step 15000, cross_ent: 0.000025, l1_norm: 27712.890625, train_acc: 1.000000, test_acc: 0.993800, loss: 1.385669, num_non_zero: 1622716\n",
      "step 16000, cross_ent: 0.000002, l1_norm: 28892.345703, train_acc: 1.000000, test_acc: 0.991800, loss: 1.444619, num_non_zero: 1617849\n",
      "step 17000, cross_ent: 0.000052, l1_norm: 29572.755859, train_acc: 1.000000, test_acc: 0.992100, loss: 1.478690, num_non_zero: 1615651\n",
      "step 18000, cross_ent: 0.000056, l1_norm: 27536.162109, train_acc: 1.000000, test_acc: 0.992200, loss: 1.376865, num_non_zero: 1619050\n",
      "step 19000, cross_ent: 1.246878, l1_norm: 27987.501953, train_acc: 0.980000, test_acc: 0.992100, loss: 2.646253, num_non_zero: 1620896\n",
      "step 20000, cross_ent: 0.000204, l1_norm: 28550.736328, train_acc: 1.000000, test_acc: 0.992500, loss: 1.427741, num_non_zero: 1619156\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-284cd58c3636>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"step %d, cross_ent: %f, l1_norm: %f, train_acc: %f, test_acc: %f, loss: %f, num_non_zero: %d\"\u001b[0m             \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcross_ent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_non_zero\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m   \u001b[0mtrain_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#print(\"test accuracy %g\"%accuracy.eval(feed_dict={\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/justin/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[0mnone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m     \"\"\"\n\u001b[1;32m-> 1267\u001b[1;33m     \u001b[0m_run_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/justin/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[1;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   2761\u001b[0m                        \u001b[1;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2762\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 2763\u001b[1;33m   \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/justin/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munique_fetch_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/justin/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m       return tf_session.TF_Run(self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 404\u001b[1;33m                                target_list)\n\u001b[0m\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(50000):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  if(i%1000 == 0):\n",
    "    saver.save(sess, checkpoint_path)\n",
    "    cross_ent, l1_norm, train_accuracy, loss_func, num_non_zero = sess.run(\n",
    "        [cross_entropy, l1_sum, accuracy, l1_loss, num_non_zero_op], \n",
    "                                  feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "    test_accuracy = get_test_accuracy()\n",
    "    print \"step %d, cross_ent: %f, l1_norm: %f, train_acc: %f, test_acc: %f, loss: %f, num_non_zero: %d\" \\\n",
    "            %(i, cross_ent, l1_norm, train_accuracy, test_accuracy, loss_func, num_non_zero)\n",
    "\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "#print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "#    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9922\n"
     ]
    }
   ],
   "source": [
    "print get_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
